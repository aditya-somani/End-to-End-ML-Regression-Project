{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac2865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5179ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\H.P\\Desktop\\Housing Regression MLE\\.venv\\Scripts\\python.exe\n",
      "3.1.1\n",
      "c:\\Users\\H.P\\Desktop\\Housing Regression MLE\\.venv\\Lib\\site-packages\\xgboost\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys, xgboost as xgb\n",
    "print(sys.executable)        # should point to .../.venv/bin/python\n",
    "print(xgb.__version__)       # should print 3.0.4\n",
    "print(xgb.__file__)          # should live under .../.venv/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbb8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8dfc82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (578916, 39)\n",
      "Eval shape: (148448, 39)\n"
     ]
    }
   ],
   "source": [
    "# 2. Load processed datasets\n",
    "train_df = pd.read_csv(r'C:\\Users\\H.P\\Desktop\\Housing Regression MLE\\data\\processed\\feature_engineered_train.csv')\n",
    "eval_df = pd.read_csv(r'C:\\Users\\H.P\\Desktop\\Housing Regression MLE\\data\\processed\\feature_engineered_eval.csv')\n",
    "\n",
    "\n",
    "# Define target + features\n",
    "target = \"price\"\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_eval, y_eval   = eval_df.drop(columns=[target]), eval_df[target]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Eval shape:\", X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf2b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Optuna objective function with MLflow\n",
    "\n",
    "def objective(trial):\n",
    "     # Define hyperparameters to tune\n",
    "    params = {\n",
    "            # Hyperparameter search spaces using Optuna's suggest methods,\n",
    "            # which sample values within specified ranges or distributions.\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),  # number of boosting rounds\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),           # max tree depth to control complexity\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),  # step size for updates\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),      # fraction of data per tree\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),  # fraction of features per tree\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),  # min sum of instance weights in a child\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),              # min loss reduction for split\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),  # L1 regularization term\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True), # L2 regularization term\n",
    "            \"random_state\": 42,                                            # fixed seed for reproducibility\n",
    "            \"n_jobs\": -1,                                                  # use all CPU cores for parallelism\n",
    "            \"tree_method\": \"hist\",                                         # fast histogram optimized tree method\n",
    "        }\n",
    "\n",
    "    # Start a nested MLflow run for this trial to log parameters and metrics\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Instantiate and train the XGBoost regressor with the sampled hyperparameters\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on evaluation set and calculate evaluation metrics\n",
    "        y_pred = model.predict(X_eval)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_eval, y_pred)))  # Root Mean Squared Error\n",
    "        mae = float(mean_absolute_error(y_eval, y_pred))           # Mean Absolute Error\n",
    "        r2 = float(r2_score(y_eval, y_pred))                        # R-squared score\n",
    "\n",
    "        # Log the parameters and metrics of this trial to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "    # Objective function returns the error metric to minimize (RMSE here)\n",
    "    return rmse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b431ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 20:15:01 INFO mlflow.tracking.fluent: Experiment with name 'xgboost_optuna_housing' does not exist. Creating a new experiment.\n",
      "[I 2025-11-03 20:15:01,583] A new study created in memory with name: no-name-fc849c59-ca5a-4524-a28f-a11de57fbfd1\n",
      "[I 2025-11-03 20:16:43,861] Trial 0 finished with value: 74977.9062564675 and parameters: {'n_estimators': 966, 'max_depth': 9, 'learning_rate': 0.07009350576049779, 'subsample': 0.8064045349478732, 'colsample_bytree': 0.7151456787570268, 'min_child_weight': 9, 'gamma': 2.6673665748902113, 'reg_alpha': 3.566143209104314, 'reg_lambda': 0.8665189968336321}. Best is trial 0 with value: 74977.9062564675.\n",
      "[I 2025-11-03 20:17:49,185] Trial 1 finished with value: 73350.27462785007 and parameters: {'n_estimators': 857, 'max_depth': 5, 'learning_rate': 0.04691942246162044, 'subsample': 0.7548198065157474, 'colsample_bytree': 0.5714158142645223, 'min_child_weight': 8, 'gamma': 3.327465677478813, 'reg_alpha': 2.1360092949405652e-07, 'reg_lambda': 0.19444210120119296}. Best is trial 1 with value: 73350.27462785007.\n",
      "[I 2025-11-03 20:18:32,813] Trial 2 finished with value: 75589.70511101838 and parameters: {'n_estimators': 349, 'max_depth': 8, 'learning_rate': 0.046500995947680715, 'subsample': 0.7133309607761005, 'colsample_bytree': 0.8644093643098805, 'min_child_weight': 3, 'gamma': 1.1752682742554221, 'reg_alpha': 0.00044248431852787474, 'reg_lambda': 1.3435217591788142e-05}. Best is trial 1 with value: 73350.27462785007.\n",
      "[I 2025-11-03 20:20:26,021] Trial 3 finished with value: 81548.60609572924 and parameters: {'n_estimators': 912, 'max_depth': 9, 'learning_rate': 0.19110143746262834, 'subsample': 0.7339185236223742, 'colsample_bytree': 0.7347408559063857, 'min_child_weight': 5, 'gamma': 4.529976642454372, 'reg_alpha': 2.1949805115014157e-05, 'reg_lambda': 1.9370560248572878e-07}. Best is trial 1 with value: 73350.27462785007.\n",
      "[I 2025-11-03 20:21:26,489] Trial 4 finished with value: 86843.7964072606 and parameters: {'n_estimators': 998, 'max_depth': 3, 'learning_rate': 0.01803621630398284, 'subsample': 0.5824730750109248, 'colsample_bytree': 0.9140297038507873, 'min_child_weight': 8, 'gamma': 1.3859969349127939, 'reg_alpha': 5.164065763602e-07, 'reg_lambda': 0.001663214502816696}. Best is trial 1 with value: 73350.27462785007.\n",
      "[I 2025-11-03 20:21:49,902] Trial 5 finished with value: 85616.25083568263 and parameters: {'n_estimators': 368, 'max_depth': 3, 'learning_rate': 0.0558039829034745, 'subsample': 0.6808783872215848, 'colsample_bytree': 0.6692361121854391, 'min_child_weight': 3, 'gamma': 4.847236292203595, 'reg_alpha': 3.332134047139324e-05, 'reg_lambda': 6.656237275721764}. Best is trial 1 with value: 73350.27462785007.\n",
      "[I 2025-11-03 20:22:13,865] Trial 6 finished with value: 79249.35202584692 and parameters: {'n_estimators': 201, 'max_depth': 8, 'learning_rate': 0.14633449358249861, 'subsample': 0.8140670236632553, 'colsample_bytree': 0.731643366924692, 'min_child_weight': 8, 'gamma': 4.428650688568466, 'reg_alpha': 3.9217338527616926e-07, 'reg_lambda': 0.6340955026948384}. Best is trial 1 with value: 73350.27462785007.\n",
      "[I 2025-11-03 20:23:45,832] Trial 7 finished with value: 69017.33435648197 and parameters: {'n_estimators': 843, 'max_depth': 8, 'learning_rate': 0.039839486699459636, 'subsample': 0.7341568080690035, 'colsample_bytree': 0.6113904727895223, 'min_child_weight': 3, 'gamma': 0.920039969221913, 'reg_alpha': 0.006868825403502387, 'reg_lambda': 1.8666324811545187e-06}. Best is trial 7 with value: 69017.33435648197.\n",
      "[I 2025-11-03 20:24:53,698] Trial 8 finished with value: 94021.63093298537 and parameters: {'n_estimators': 413, 'max_depth': 10, 'learning_rate': 0.2433438091382995, 'subsample': 0.8531888092779707, 'colsample_bytree': 0.803674636286049, 'min_child_weight': 6, 'gamma': 3.9163426270249757, 'reg_alpha': 3.888341024606247e-07, 'reg_lambda': 0.7882452318010126}. Best is trial 7 with value: 69017.33435648197.\n",
      "[I 2025-11-03 20:25:17,593] Trial 9 finished with value: 77454.62448870236 and parameters: {'n_estimators': 342, 'max_depth': 4, 'learning_rate': 0.10989386366915813, 'subsample': 0.9780107409843968, 'colsample_bytree': 0.9774294131832828, 'min_child_weight': 4, 'gamma': 1.7515958067373283, 'reg_alpha': 2.297615723026255e-06, 'reg_lambda': 0.006009199824731949}. Best is trial 7 with value: 69017.33435648197.\n",
      "[I 2025-11-03 20:26:26,643] Trial 10 finished with value: 74587.16800498261 and parameters: {'n_estimators': 718, 'max_depth': 6, 'learning_rate': 0.010253879447974113, 'subsample': 0.5141138433120203, 'colsample_bytree': 0.5155985821032396, 'min_child_weight': 1, 'gamma': 0.027862156095058932, 'reg_alpha': 0.021808117510360374, 'reg_lambda': 7.06423001880987e-08}. Best is trial 7 with value: 69017.33435648197.\n",
      "[I 2025-11-03 20:27:29,912] Trial 11 finished with value: 70668.18957857564 and parameters: {'n_estimators': 759, 'max_depth': 6, 'learning_rate': 0.03396506669102268, 'subsample': 0.6284397289245717, 'colsample_bytree': 0.5754806513416388, 'min_child_weight': 10, 'gamma': 3.1965412440390213, 'reg_alpha': 0.008564709736958758, 'reg_lambda': 1.4562401833232632e-05}. Best is trial 7 with value: 69017.33435648197.\n",
      "[I 2025-11-03 20:28:41,924] Trial 12 finished with value: 70547.13185620696 and parameters: {'n_estimators': 725, 'max_depth': 7, 'learning_rate': 0.028407174321001788, 'subsample': 0.6140977804647397, 'colsample_bytree': 0.6285261936485234, 'min_child_weight': 10, 'gamma': 2.604937538577318, 'reg_alpha': 0.018244436654160357, 'reg_lambda': 8.722210431502886e-06}. Best is trial 7 with value: 69017.33435648197.\n",
      "[I 2025-11-03 20:29:44,645] Trial 13 finished with value: 71845.63532011109 and parameters: {'n_estimators': 594, 'max_depth': 7, 'learning_rate': 0.025574294452749106, 'subsample': 0.6082078560790037, 'colsample_bytree': 0.6242017264597697, 'min_child_weight': 1, 'gamma': 0.29502067214781147, 'reg_alpha': 0.3230394893506878, 'reg_lambda': 4.503245141623623e-06}. Best is trial 7 with value: 69017.33435648197.\n",
      "[I 2025-11-03 20:30:41,357] Trial 14 finished with value: 69578.00163139537 and parameters: {'n_estimators': 625, 'max_depth': 7, 'learning_rate': 0.01648667764973658, 'subsample': 0.5261226944306134, 'colsample_bytree': 0.5020193150437458, 'min_child_weight': 6, 'gamma': 2.0489360873311444, 'reg_alpha': 0.0048334312212713875, 'reg_lambda': 1.0327122884710583e-06}. Best is trial 7 with value: 69017.33435648197.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 843, 'max_depth': 8, 'learning_rate': 0.039839486699459636, 'subsample': 0.7341568080690035, 'colsample_bytree': 0.6113904727895223, 'min_child_weight': 3, 'gamma': 0.920039969221913, 'reg_alpha': 0.006868825403502387, 'reg_lambda': 1.8666324811545187e-06}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path # for OS-independent path handling\n",
    "\n",
    "# Set MLflow tracking URI to a local directory where experiment data is saved\n",
    "mlflow_path = Path(r'C:\\Users\\H.P\\Desktop\\Housing Regression MLE\\mlruns').as_uri() # Convert path to URI format\n",
    "mlflow.set_tracking_uri(mlflow_path)\n",
    "\n",
    "# Set or create MLflow experiment name for grouping runs\n",
    "mlflow.set_experiment(\"xgboost_optuna_housing\")\n",
    "\n",
    "# Create an Optuna study; direction=\"minimize\" means it tries to minimize the objective function result (rmse)\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Execute the study optimization for 15 trials\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "# Print the best found hyperparameters after tuning\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05d4468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tuned model performance:\n",
      "MAE: 30956.589210415932\n",
      "RMSE: 71976.29727484864\n",
      "R²: 0.9599650736814732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\H.P\\Desktop\\Housing Regression MLE\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1115: UserWarning: [20:33:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/11/03 20:33:32 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/11/03 20:33:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# 5. Train final model with best params and log to MLflow\n",
    "best_params = study.best_trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_eval)\n",
    "\n",
    "mae = mean_absolute_error(y_eval, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_eval, y_pred))\n",
    "r2 = r2_score(y_eval, y_pred)\n",
    "\n",
    "print(\"Final tuned model performance:\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Log final model\n",
    "with mlflow.start_run(run_name=\"best_xgboost_model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "    mlflow.xgboost.log_model(best_model, name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b944d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing-regression-mle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
